<!DOCTYPE html>

<html lang="en-us">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  

  <title>Compatibility with Various SQL Engines - Sqlflow</title>
  <link rel="stylesheet" href="/assets/css/just-the-docs.css">

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-17331483-8', '');
      ga('send', 'pageview');
    </script>
    <script async src="https://www.google-analytics.com/analytics.js"></script>
  

  
    <script type="text/javascript" src="/assets/js/vendor/lunr.min.js"></script>
  
  <script type="text/javascript" src="/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>

  <div class="page-wrap">
    <div class="side-bar">
      <a href="" class="site-title fs-6 lh-tight">Sqlflow</a>
      <span class="fs-3"><button class="js-main-nav-trigger navigation-list-toggle btn btn-outline" type="button" data-text-toggle="Hide">Menu</button></span>
      <div class="navigation main-nav js-main-nav">
        <nav role="navigation" aria-label="Main navigation">
  <ul class="navigation-list">
    
    
      
        
          <li class="navigation-list-item">
            
            <a href="/doc/walkthrough.html" class="navigation-list-link">SQLFlow: Code Walkthrough</a>
            
          </li>
        
      
    
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="/doc/build-tensorflow.html" class="navigation-list-link">Build TensorFlow from Source Code using Docker</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="/doc/build.html" class="navigation-list-link">Canonical Development Environment</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="/doc/close_producer_from_consumer.html" class="navigation-list-link">Closing the producer goroutine from the consumer</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item active">
            
            <a href="/doc/database_abstraction_layer.html" class="navigation-list-link active">Compatibility with Various SQL Engines</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="/doc/mysql-setup.html" class="navigation-list-link">Run MySQL Server and Client in Docker Containers</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="/doc/pipe.html" class="navigation-list-link">Piping Responses</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="/doc/quickstart.html" class="navigation-list-link">Quick start</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="/doc/sql_parser.html" class="navigation-list-link">Extended SQL Parser Design</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="/doc/submitter.html" class="navigation-list-link">Submitter</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="/doc/syntax.html" class="navigation-list-link">SQLFlow: Design Doc</a>
            
          </li>
        
      
    
      
    
  </ul>
</nav>

      </div>
      <footer role="contentinfo" class="site-footer">
        <p class="text-small text-grey-dk-000 mb-0">This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</p>
      </footer>
    </div>
    <div class="main-content-wrap js-main-content" tabindex="0">
      <div class="page-header">
        <div class="main-content">
          
          <div class="search js-search">
            <div class="search-input-wrap">
              <input type="text" class="js-search-input search-input" tabindex="0" placeholder="Search Sqlflow" aria-label="Search Sqlflow" autocomplete="off">
              <svg width="14" height="14" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="search-icon"><title>Search</title><g fill-rule="nonzero"><path d="M17.332 20.735c-5.537 0-10-4.6-10-10.247 0-5.646 4.463-10.247 10-10.247 5.536 0 10 4.601 10 10.247s-4.464 10.247-10 10.247zm0-4c3.3 0 6-2.783 6-6.247 0-3.463-2.7-6.247-6-6.247s-6 2.784-6 6.247c0 3.464 2.7 6.247 6 6.247z"/><path d="M11.672 13.791L.192 25.271 3.02 28.1 14.5 16.62z"/></g></svg>
            </div>
            <div class="js-search-results search-results-wrap"></div>
          </div>
          
          
            <ul class="list-style-none text-small mt-md-1 mb-md-1 pb-4 pb-md-0 js-aux-nav aux-nav">
              
                <li class="d-inline-block my-0"><a href="https://github.com/sql-machine-learning/sqlflow">GitHub</a></li>
              
            </ul>
          
        </div>
      </div>
      <div class="main-content">
        
          
        
        <div id="main-content" class="page-content" role="main">
          <h1 id="compatibility-with-various-sql-engines">Compatibility with Various SQL Engines</h1>

<p>SQLFlow interacts with SQL engines like MySQL and Hive, while different SQL engines use variants of SQL syntax, it is important for SQLFlow to have an abstraction layer that hides such differences.</p>

<p>SQLFlow calls Go’s <a href="https://golang.org/pkg/database/sql/">standard database API</a>. The submitter programs generated by SQLFlow call Python’s <a href="https://www.python.org/dev/peps/pep-0249/">database API</a>.  Both APIs abstract the interface to various SQL engines; however, they are insufficient for SQLFlow to work.  In this document, we examine all interactions between SQLFlow and the SQL engine so to identify what SQLFlow authors have to abstract in addition to calling Go’s and Python’s database APIs.</p>

<h2 id="data-operations-in-go">Data Operations in Go</h2>

<h3 id="data-retrieval">Data Retrieval</h3>

<p>The basic idea of SQLFlow is to extend the SELECT statement of SQL to have the TRAIN and PREDICT clauses.  For more discussion, please refer to the <a href="/doc/syntax.md">syntax design</a>.  SQLFlow translates such “extended SQL statements” into submitter programs, which forward the part from SELECT to TRAIN or PREDICT, which we call the “standard part”, to the SQL engine.  SQLFlow also accepts the SELECT statement without TRAIN or PREDICt clauses and would forward such “standard statements” to the engine.  It is noticeable that the “standard part” or “standard statements” are not standardized.  For example, various engines use different syntax for joining.</p>

<ul>
  <li>MySQL: <code class="highlighter-rouge">SELECT pet.name, comment FROM pet, event WHERE pet.name =event.name;</code> with keyword <code class="highlighter-rouge">WHERE</code> .</li>
  <li>Hive: <code class="highlighter-rouge">SELECT pet.name, comment FROM pet JOIN event ON (pet.name =event.name)</code> with keyword <code class="highlighter-rouge">JOIN</code> and <code class="highlighter-rouge">ON</code>.</li>
  <li>ODPS and SQLite use either <code class="highlighter-rouge">INNER JOIN</code> or <code class="highlighter-rouge">OUTER JOIN</code>.</li>
</ul>

<p>Fortunately, as SQLFlow forwards the above parts to the engine,  it doesn’t have to care much about the differences above.</p>

<h3 id="metadata-retrieval">Metadata Retrieval</h3>

<p>To verify the semantics of users’ inputs, SQLFlow needs to retrieve the schema of tables.  For example, the input might be</p>

<pre><code class="language-SQL">SELECT name, age, income FROM employee TRAIN DNNRegressor WITH hidden_layers=[10,50,10] COLUMN name, agee LABEL income;
</code></pre>

<p>In the above example, the user misspelled the field name <code class="highlighter-rouge">age</code> in the COLUMN clause as “agee”. SQLFlow must be able to find that out.</p>

<p>To do that, SQLFlow needs to query the field names from the SQL engine.  However, different engines use various syntax. For example:</p>

<ul>
  <li>MySQL: <code class="highlighter-rouge">DESCRIBE/DESC employee;</code></li>
  <li>Hive: <code class="highlighter-rouge">DESCRIBE FORMATTED employee;</code></li>
  <li>ODPS: <code class="highlighter-rouge">DESC employee;</code></li>
  <li>SQLite: <code class="highlighter-rouge">PRAGMA table_info([employee]);</code></li>
</ul>

<p>The returned data format varies too. Our solution to avoid such differences is not-to-use-them; instead, SQLFlow retrieves the table schema by running a query like <code class="highlighter-rouge">SELECT * FROM employee LIMIT 1;</code> and inferring field types using the mechanism called <a href="https://golang.org/pkg/database/sql/#ColumnType.DatabaseTypeName">DatabaseTypeName</a> provided by SQL engines drivers beneath the Go’s standard database API.</p>

<h3 id="prepare-prediction-table">Prepare Prediction Table</h3>

<p>A SQLFlow prediction job writes its prediction results into a table. It prepares the prediction table by</p>

<ol>
  <li>Dropping previous prediction table <code class="highlighter-rouge">DROP TABLE IF EXISTS my_table;</code></li>
  <li>Creating table with schema <code class="highlighter-rouge">CREATE TABLE my_table (name1, type1, name2 type2);</code></li>
</ol>

<p>Most SQL engines, including MySQL, Hive, ODPS, SQLite, support both statements.</p>

<h3 id="translate-database-column-type-to-tensorflow-feature-column-type">Translate Database Column Type to TensorFlow Feature Column Type</h3>

<p>After retrieving database column type name through <a href="https://golang.org/pkg/database/sql/#ColumnType.DatabaseTypeName">DatabaseTypeName</a>, we can derive TensorFlow’s <a href="https://www.tensorflow.org/guide/feature_columns">feature column</a> type via a mapping such as <code class="highlighter-rouge">{"FLOAT", "DOUBLE"} -&gt; tf.numeric_column</code>.</p>

<h3 id="save-model">Save Model</h3>

<p>SQLFlow saves trained ML model by dumping the serialized the model directory into a table. It first creates a table by <code class="highlighter-rouge">CREATE TABLE IF NOT EXISTS %s (id INT AUTO_INCREMENT, block BLOB, PRIMARY KEY (id))</code> and insert blobs by <code class="highlighter-rouge">INSERT INTO %s (block) VALUES(?)</code>.</p>

<p>Note that Hive and ODPS doesn’t have <code class="highlighter-rouge">BLOB</code> type, we need to use <code class="highlighter-rouge">BINARY</code> (docs at <a href="https://help.aliyun.com/document_detail/27821.html?spm=a2c4g.11186623.6.577.768231deoru03E">ODPS</a>, <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types#LanguageManualTypes-MiscTypes">Hive</a>) instead.</p>

<p>Also, note that Hive and ODPS doesn’t support <code class="highlighter-rouge">AUTO_INCREMENT</code>, we need to implemented auto increment logic in <code class="highlighter-rouge">sqlfs</code>.</p>

<h3 id="load-model">Load Model</h3>

<p>SQLFlow loads trained ML model by reading rows in a table and deserializing the blob to a model directory.</p>

<p>It reads rows by running <code class="highlighter-rouge">SELECT block FROM %s ORDER BY id</code>, which is supported by most databases.</p>

<h2 id="data-operations-in-python">Data Operations in Python</h2>

<h3 id="connect-to-sql-engines">Connect to SQL Engines</h3>

<p>Thanks to the Python database API, connecting to different databases follows a similar API.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">conn</span> <span class="o">=</span> <span class="n">mysql</span><span class="o">.</span><span class="n">connector</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">user</span><span class="o">=</span><span class="s">'scott'</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="s">'password'</span><span class="p">,</span>
                               <span class="n">host</span><span class="o">=</span><span class="s">'127.0.0.1'</span><span class="p">,</span>
                               <span class="n">database</span><span class="o">=</span><span class="s">'employees'</span><span class="p">)</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s">'path/to/your/sqlite/file'</span><span class="p">)</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">pyhive</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s">'localhost'</span><span class="p">)</span>

<span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s">'select * from my_table;'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="insert-prediction-result-into-prediction-table">Insert Prediction Result into Prediction Table</h3>

<p>Python database API provides <code class="highlighter-rouge">execute_many(sql, value)</code>  to insert multiple values at once. So one can prepare the following insertion statement. Please be aware that MySQL and SQLite use <code class="highlighter-rouge">INSERT INTO</code> to insert rows while Hive and ODPS use <code class="highlighter-rouge">INSERT INTO TABLE</code>.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- MySQL, SQLite</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">table_name</span> <span class="k">VALUES</span> <span class="p">(</span><span class="n">value1</span><span class="p">,</span> <span class="n">value2</span><span class="p">,</span> <span class="n">value3</span><span class="p">,</span> <span class="p">...);</span>
<span class="c1">-- Hive, ODPS</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="k">table_name</span> <span class="k">VALUES</span> <span class="p">(</span><span class="n">value1</span><span class="p">,</span> <span class="n">value2</span><span class="p">,</span> <span class="n">value3</span><span class="p">,</span> <span class="p">...);</span>
</code></pre></div></div>




          
        </div>
      </div>
    </div>
  </div>

</body>
</html>
